---
title: "Class07: Machine Learning 1"
author: "Montserrat (A16536527)"
format: pdf
---

Today we will begin our exploration of some "classical" machine learning approaches. we will start with clustering:


Lets first make up some data to cluster where we know what the answer should be 

```{r}
#rnorm(1000)
hist(rnorm(1000))
```
```{r}
x <-c(rnorm(30,mean=3),rnorm(30, mean=-3))
y <- rev(x)

x <-cbind(x,y)
#c in cbind stands for column bind so rbind is row bind, puts them side to side
```
A wee peak at x with `plot(x)`

```{r}
plot(x)
```
The main function in "base" R for K-mean clustering is called `kmeans()`

```{r}
kmeans(x,centers=2)
k<-kmeans(x,centers=2)
# only 2 required arguments, x and centers
```

>Q. how big are the clusters (i.e their size?)

```{r}
k$size
```
>Q clusters?

```{r}
k$cluster
```

```{r}
k
```

>Q. make a plot of our data colored by cluster assignment-- i.e. make a result figure 

```{r}
plot(x,col=k$cluster)
points(k$centers,col="blue",pch=15)
```
>Q. cluster with k-means into 4 clusters and plot your results as above?

```{r}
k4 <-kmeans(x,centers=4)
plot(x,col=k4$cluster)
points(k4$centers,col="blue",pch=15)

```
>Q. run kmeans with centers(i.e. values of k) equal 1 to 6 

```{r}
k1 <- kmeans(x,centers=1)$tot.withinss
k2 <- kmeans(x,centers=2)$tot.withinss
k3 <-kmeans(x,centers=3)$tot.withinss
k4 <- kmeans(x,centers=4)$tot.withinss
k5 <- kmeans(x,centers=5)$tot.withinss
k6 <- kmeans(x,centers=6)$tot.withinss

ans <- c(k1,k2,k3,k4,k5,k6)

```

or use a for loop 

```{r}
ans <- NULL
for(i in 1:6) {
  ans <- c(ans,kmeans(x,centers=i)$tot.withinss)
}
```

Make a "scree-plot'

```{r}
plot(ans,typ="b")
```
## Hierarchical Clustering 

The main function in "base: R for this is called `hclust`
help key = 
```{r}
#dist(x)
d<-dist(x)
hc<-hclust(d)
hc

```
```{r}
plot(hc)
abline(h=7,col="red")
```
to obtain clusters from our `hclut` result object **hc** we "cut" the tree to yield diffferent subbranches. for this we use the `cutree()`

```{r}
grps <- cutree(hc,h=7)
plot(x, col=grps)
```
kmeans(x,centers=)
hclust(dist(x))

```{r}
library(pheatmap)
pheatmap(x)
```

## Principal Component Analysis (PCA)


```{r}
url <- "https://tinyurl.com/UK-foods"
x <- read.csv(url)
```


>Q1. How many rows and columns are in your new data frame named x? What R functions could you use to answer this questions?

```{r}
dim(x)

#preview the first 6 rows 
head(x)
```

```{r}
# Note how the minus indexing works
rownames(x) <- x[,1]
x <- x[,-1]
head(x)

#alternative approach to setting correct row names 
#x <- read.csv(url, row.names=1)
#head(x)
```
>Q2. Which approach to solving the ‘row-names problem’ mentioned above do you prefer and why? Is one approach more robust than another under certain circumstances?

I prefer the second choice because it is more robust and running x <- x[,-1]) leads to elimation of one column every time you run it 


```{r}
# Using base R
barplot(as.matrix(x), beside=T, col=rainbow(nrow(x)))
```

```{r}
barplot(as.matrix(x), col=rainbow(nrow(x)))
```
>Q3: Changing what optional argument in the above barplot() function results in the following plot?

remove `beside=T`

## Side-note: Using ggplot and the need for “tidy” data




```{r}
# Currently we have wide format
dim(x)
head(x)
```

```{r}
library(tidyr)

# Convert data to long format for ggplot with `pivot_longer()`
x_long <- x |> 
          tibble::rownames_to_column("Food") |> 
          pivot_longer(cols = -Food, 
                       names_to = "Country", 
                       values_to = "Consumption")

dim(x_long)
```

```{r}
head(x_long)
```

```{r}
# Create grouped bar plot
library(ggplot2)

ggplot(x_long) +
  aes(x = Country, y = Consumption, fill = Food) +
  geom_col(position = "dodge") +
  theme_bw()
```

>Q4: Changing what optional argument in the above ggplot() code results in a stacked barplot figure?

```{r}
ggplot(x_long) +
  aes(x = Country, y = Consumption, fill = Food) +
  geom_col(position = "stack") +
  theme_bw()
```

>Q5: We can use the pairs() function to generate all pairwise plots for our countries. Can you make sense of the following code and resulting figure? What does it mean if a given point lies on the diagonal for a given plot?

```{r}
pairs(x, col=rainbow(nrow(x)), pch=16)
```


```{r}
library(pheatmap)

pheatmap( as.matrix(x) )
```
>Q6. Based on the pairs and heatmap figures, which countries cluster together and what does this suggest about their food consumption patterns? Can you easily tell what the main differences between N. Ireland and the other countries of the UK in terms of this data-set?

It looks like Wales and England are quite similar in their consumption of these food but still difficult to tell what is going on in the dataset 

##PCA to the rescue 

The main function in "base" R for PCA is called `prcomp()`

as we want to do PCA on the food data across countries for the different countries we will want the foods in the columns 
```{r}
pca<- prcomp(t(x))
summary(pca)
```
telling you the first one captures about 67% of variance, PC2 abouot 29% and so on 

Our result object is called `pca` and it has a `$x` component that we will look at first 

```{r}
pca$x

cols <- c("red","blue","orange","green")
ggplot(pca$x)+
  aes(PC1,PC2,label=rownames(pca$x))+
  geom_point(col=cols)+ geom_text()

```

Another major result out of PCA is the so called "variable loadings" or `$rotation`. tells us how the original variables (foods) contribute PCs (i.e. our new axis)  

```{r}
pca$rotation
```

```{r}
ggplot(pca$rotation) +aes(PC1, rownames(pca$rotation)) + geom_col()
```


